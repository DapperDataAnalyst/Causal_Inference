---
title: "Homework 3.1"
output: html_document
date: "2023-10-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1:
```{r}
library(rstanarm)
library(rstan)



advertising <- read.table(file = 'https://raw.githubusercontent.com/DapperDataAnalyst/Causal_Inference/main/advertising.txt', header = T, sep = "\t", fileEncoding = "UTF-8")

fit <- lm(sales_millions ~ minutes, data = advertising)
summary(fit)

fit_glm <- stan_glm(sales_millions ~ minutes, data = advertising, refresh=0)
summary(fit_glm)
sims <- as.matrix(fit_glm)
min(sims[,2])

new <- data.frame(minutes=20)
y_pred <- posterior_predict(fit_glm, newdata=new)
quantile(y_pred, probs = 0.95)
```

## Question 2:
```{r}
library(ggplot2)


beauty <- read.table(file = 'https://raw.githubusercontent.com/DapperDataAnalyst/Causal_Inference/main/beauty.txt', header = T, sep = "\t", fileEncoding = "UTF-8")

model <- stan_glm(eval ~ beauty + female + age + minority + nonenglish + lower, data = beauty, refresh=0)
summary(model)
# Create a scatterplot of the data
data_plot <- ggplot(beauty, aes(x = beauty, y = eval)) +
  geom_point() +  # Scatterplot points
  labs(x = "Beauty", y = "Evaluations") +  # Axis labels
  theme_minimal()  # Minimalist theme

# Add the fitted model line (excluding unreasonable predictors)
data_plot <- data_plot + geom_smooth(method = "lm",
                                     formula = y ~ x,
                                     aes(color = "Fitted Model"),
                                     data = subset(beauty, select = c("eval", "beauty")))

# Display the plot
print(data_plot)
```

## Question 3:
```{r}
challenger <- read.table(file = 'https://raw.githubusercontent.com/DapperDataAnalyst/Causal_Inference/main/challenger.txt', header = T, sep = "\t", fileEncoding = "UTF-8")

# Part a)
model1 <- stan_glm(Fail ~ Temperature, family=binomial(link="logit"), data=challenger,
                  refresh=0)
summary(model1) # Note that point estimates directly out of the model are on the log-odds scale

# Part b)
exp(model1$coefficients[2])

new1 <- data.frame(Temperature=69)
pred_prob1 <- predict(model1, type="response", newdata=new1)
new2 <- data.frame(Temperature=70)
pred_prob2 <- predict(model1, type="response", newdata=new2)
pred_prob2 - pred_prob1

# Part e)
challenger$Temperature_Celsius <- (challenger$Temperature - 32) * (5/9)
model2 <- stan_glm(Fail ~ Temperature_Celsius, family=binomial(link="logit"), data=challenger,
                   refresh=0)
summary(model2) # Note that point estimates directly out of the model are on the log-odds scale

# Part f)
newF1 <- data.frame(Temperature=70)
pred_probF1 <- predict(model1, type="response", newdata=newF1)
newF2 <- data.frame(Temperature=65)
pred_probF2 <- predict(model1, type="response", newdata=newF2)
pred_probF2 - pred_probF1

# linpredF1 <- posterior_linpred(model1, newdata=newF1)
# linpredF2 <- posterior_linpred(model1, newdata=newF2)
# mean(linpredF2 - linpredF1) # This is what I originally answered and it is wrong
poster_diff <- posterior_predict(model1, newdata = newF2) - posterior_predict(model1, newdata = newF1)
mean(poster_diff)

# Part g)
# sd(linpredF2 - linpredF1) # This is what I originally answered and it is wrong
sd(poster_diff)


series <- data.frame(Temperature=1:100)
points <- predict(model1, type="response", newdata = series)
# points <- posterior_predict(model1, newdata = series)
# points <- posterior_epred(model1, newdata = series)
points <- posterior_linpred(model1, newdata = series)


data <- data.frame(x = series, y = points)

ggplot(data, aes(Temperature, y.1)) +
  geom_line() +
  labs(x = "X-Axis Label", y = "Y-Axis Label", title = "Line Plot of Your Function")
```


